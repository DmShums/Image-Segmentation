# Image Segmentation
This code is used for performing image segmentation tasks, particularly in the context of ship detection in satellite images.

## Dataset Overview
The dataset consists of images and corresponding ship segmentation masks. The image data is stored in two directories: train_v2 and test_v2. Additionally, the ship segmentation information is provided in a CSV file named train_ship_segmentations_v2.csv.

## Sample Data
Train Data: Contains images used for training the model.
Test Data: Contains images used for evaluating the model.

## Mask Creation
The provided CSV file is used to create binary masks indicating the presence of ships in the images. The masks are generated by decoding the Run Length Encoding (RLE) encoded pixel data.

## Data Transformation and Loading
The images and masks are resized to a standard size of 256x256 pixels for ease of processing. They are then converted into PyTorch tensors and organized into batches using the DataLoader class for efficient training.

## U-Net Architecture
The U-Net neural network architecture is employed for semantic segmentation tasks. The U-Net model consists of downsampling and upsampling paths with skip connections to preserve spatial information.

## Model Training
The U-Net model is trained using the Adam optimizer with a learning rate of 1e-6. The training process involves iterating through the dataset for a specified number of epochs. During training, the model's performance is periodically evaluated, and checkpoints are saved for future use.

## Evaluation
After training, the model's accuracy is evaluated on the test dataset. The accuracy is measured based on the number of correctly classified pixels and the Dice coefficient, which quantifies the overlap between predicted and ground truth masks.